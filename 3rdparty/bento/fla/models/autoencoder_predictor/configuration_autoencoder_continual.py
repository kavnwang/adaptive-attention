# -*- coding: utf-8 -*-

from typing import Optional

from fla.models.autoencoder.configuration_autoencoder import AutoencoderConfig


class AutoencoderPredictorConfig(AutoencoderConfig):
    # Dedicated predictor type so train.py can detect it
    model_type = "autoencoder_predictor"

    def __init__(
        self,
        hidden_size: int = 2048,
        num_hidden_layers: int = 24,
        num_hidden_layers_post: int = 0,
        num_heads: int = 32,
        num_kv_heads: Optional[int] = None,
        qkv_bias: bool = False,
        qk_norm: bool = False,
        window_size: Optional[int] = None,
        rope_theta: Optional[float] = 10000.0,
        max_position_embeddings: int = 16384,
        hidden_ratio: Optional[int] = 4,
        intermediate_size: Optional[int] = None,
        hidden_act: str = "swish",
        initializer_range: float = 0.02,
        elementwise_affine: Optional[bool] = True,
        norm_eps: float = 1e-6,
        use_cache: bool = True,
        pad_token_id: Optional[int] = None,
        bos_token_id: int = 1,
        eos_token_id: int = 2,
        tie_word_embeddings: bool = False,
        fuse_norm: bool = True,
        fuse_swiglu: bool = True,
        fuse_cross_entropy: bool = True,
        fuse_linear_cross_entropy: bool = False,
        use_l2warp: bool = False,
        vocab_size: int = 32000,
        compression_ratio: float = 0.0625,
        compression_depth: int = 2,
        upsample_depth: int = 1,
        compression_layer_idx: Optional[int] = 6,
        masked_tokens: int = 0,
        compression_tokens: int = 0,
        **kwargs,
    ):
        super().__init__(
            hidden_size=hidden_size,
            num_hidden_layers=num_hidden_layers,
            num_hidden_layers_post=num_hidden_layers_post,
            num_heads=num_heads,
            num_kv_heads=num_kv_heads,
            qkv_bias=qkv_bias,
            qk_norm=qk_norm,
            window_size=window_size,
            rope_theta=rope_theta,
            max_position_embeddings=max_position_embeddings,
            hidden_ratio=hidden_ratio,
            intermediate_size=intermediate_size,
            hidden_act=hidden_act,
            initializer_range=initializer_range,
            elementwise_affine=elementwise_affine,
            norm_eps=norm_eps,
            use_cache=use_cache,
            pad_token_id=pad_token_id,
            bos_token_id=bos_token_id,
            eos_token_id=eos_token_id,
            tie_word_embeddings=tie_word_embeddings,
            fuse_norm=fuse_norm,
            fuse_swiglu=fuse_swiglu,
            fuse_cross_entropy=fuse_cross_entropy,
            fuse_linear_cross_entropy=fuse_linear_cross_entropy,
            use_l2warp=use_l2warp,
            vocab_size=vocab_size,
            compression_ratio=compression_ratio,
            compression_depth=compression_depth,
            upsample_depth=upsample_depth,
            compression_layer_idx=compression_layer_idx,
            masked_tokens=masked_tokens,
            compression_tokens=compression_tokens,
            **kwargs,
        )
