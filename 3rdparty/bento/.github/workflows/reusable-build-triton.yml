name: Reusable Triton Build Job

on:
  workflow_call:
    # Define inputs that the caller workflow can provide.
    # This makes the workflow flexible for different scenarios.
    inputs:
      runner:
        description: 'The runner label for the job, in JSON array format'
        required: true
        type: string
      arch:
        description: 'Architecture (x86_64 or aarch64)'
        required: true
        type: string
      timeout:
        description: 'Job timeout in minutes'
        required: false
        type: string
        default: '720'

      checkout-ref:
        description: 'The branch, tag, or SHA to checkout. Defaults to the "main" branch.'
        required: false
        type: string
        default: 'main'

      cibw-build:
        description: 'The CIBW_BUILD environment variable to select Python versions'
        required: false
        type: string
        default: 'auto'
      cibw-skip:
        description: 'The CIBW_SKIP environment variable to exclude Python versions'
        required: false
        type: string
        default: ''

      package-name:
        description: 'The final package name (e.g., triton or triton-nightly)'
        required: true
        type: string

    secrets:
      FLA_TRITON_PYPI_PASSWD:
        required: true
      A770_PROXY_ENV:
        required: false
      PI_PROXY_ENV:
        required: false

jobs:
  build-and-publish:
    runs-on: ${{ fromJson(inputs.runner) }}
    timeout-minutes: ${{ fromJson(inputs.timeout) }}

    steps:
      - name: Prune stale docker containers
        run: |
          echo "Current runner: ${{ runner.name }}"
          docker container prune -f

      - name: Checkout Triton at specified ref
        uses: actions/checkout@v4
        with:
           repository: triton-lang/triton
           ref: ${{ inputs.checkout-ref }}
           path: triton

      - id: check-version
        name: Set up version
        working-directory: triton
        run: |
          echo "new_commit=true" >> "$GITHUB_OUTPUT"
          export BUILD_DATE=$(date -u +"%Y%m%d%H%M")
          echo "BUILD_DATE=$BUILD_DATE" >> $GITHUB_ENV
          python3 -m pip install wheel cibuildwheel -U
          WHEEL_PATH=$(whereis wheel | cut -d: -f2 | xargs)
          if [ -z "$WHEEL_PATH" ]; then
            echo "ERROR: wheel command not found. This will cause the build to fail later."
            exit 1
          else
            echo "wheel command found at: $WHEEL_PATH"
          fi

      - name: Patch setup.py
        if: ${{ steps.check-version.outputs.new_commit == 'true' }}
        working-directory: triton
        run: |
          echo "" >> python/setup.cfg
          echo "[build_ext]" >> python/setup.cfg
          echo "base-dir=/project" >> python/setup.cfg

      - name: Patch setup.py mirror
        if: ${{ steps.check-version.outputs.new_commit == 'true' }}
        working-directory: triton
        run: |
          # ... same script to patch the URL ...
          LLVM_PROTO="http"
          [[ "${{ runner.name }}" == "intel-a770" || "${{ runner.name }}" == "pi" || "${{ runner.name }}" == "n100" ]] || LLVM_PROTO="https"

          file_path="python/setup.py"
          [ -f "$file_path" ] || file_path="setup.py"

          sed -i "s|https://oaitriton.blob.core.windows.net/public/llvm-builds/|${LLVM_PROTO}://llvm.fla-org.com/|g" "$file_path"
          grep "llvm.fla-org.com" "$file_path" || (echo "URL replacement failed"; exit 1)

      - name: Build wheels
        if: ${{ steps.check-version.outputs.new_commit == 'true' }}
        working-directory: triton
        run: |
          # Environment setup based on runner name
          export CIBW_ENVIRONMENT="TRITON_BUILD_WITH_CLANG_LLD=1"

          case "${{ runner.name }}" in
            intel-a770)
              export CIBW_ENVIRONMENT="$CIBW_ENVIRONMENT SOCKS_PROXY=${{ secrets.A770_PROXY_ENV }} ALL_PROXY=${{ secrets.A770_PROXY_ENV }} HTTPS_PROXY=${{ secrets.A770_PROXY_ENV }} PIP_INDEX_URL=https://mirrors.aliyun.com/pypi/simple/"
              ;;
            pi)
              export CIBW_ENVIRONMENT="$CIBW_ENVIRONMENT SOCKS_PROXY=${{ secrets.PI_PROXY_ENV }} ALL_PROXY=${{ secrets.PI_PROXY_ENV }} HTTPS_PROXY=${{ secrets.PI_PROXY_ENV }} PIP_INDEX_URL=https://mirrors.aliyun.com/pypi/simple/"
              ;;
            n100)
              export CIBW_ENVIRONMENT="$CIBW_ENVIRONMENT SOCKS_PROXY=${{ secrets.PVE_PROXY_ENV }} ALL_PROXY=${{ secrets.PVE_PROXY_ENV }} HTTPS_PROXY=${{ secrets.PVE_PROXY_ENV }} PIP_INDEX_URL=https://mirrors.aliyun.com/pypi/simple/"
              ;;
            *)
              ;;
          esac

          # Prerequisite installation based on runner name
          case "${{ runner.name }}" in
            intel-a770|pi|n100)
              CIBW_BEFORE_ALL='
                echo "${{ secrets.LLVM_MIRROR_IP }} llvm.fla-org.com" >> /etc/hosts
                sed -e "s|^mirrorlist=|#mirrorlist=|g" \
                    -e "s|^# baseurl=https://repo.almalinux.org|baseurl=https://mirrors.aliyun.com|g" \
                    -i.bak /etc/yum.repos.d/almalinux*.repo
                dnf install -y --best clang lld'
                export CIBW_CONTAINER_ENGINE="docker;create_args: --network host"
              ;;
            *)
              CIBW_BEFORE_ALL='dnf install -y --best clang lld'
              ;;
          esac

          case "${{ runner.name }}" in
            intel-a770)
              CIBW_BEFORE_ALL="$CIBW_BEFORE_ALL && git config --global http.proxy ${{ secrets.A770_PROXY_ENV }} && git config --global https.proxy ${{ secrets.A770_PROXY_ENV }}"
              ;;
            pi)
              CIBW_BEFORE_ALL="$CIBW_BEFORE_ALL && git config --global http.proxy ${{ secrets.PI_PROXY_ENV }} && git config --global https.proxy ${{ secrets.PI_PROXY_ENV }}"
              ;;
            n100)
              CIBW_BEFORE_ALL="$CIBW_BEFORE_ALL && git config --global http.proxy ${{ secrets.PVE_PROXY_ENV }} && git config --global https.proxy ${{ secrets.PVE_PROXY_ENV }}"
              ;;
            *)
              ;;
          esac

          # Set ccache configuration based on runner name
          case "${{ runner.name }}" in
            pi)
              CIBW_BEFORE_ALL="$CIBW_BEFORE_ALL && dnf install -y ccache \
                && mkdir -p /host${{ secrets.PI_CCACHE_DIR }} \
                && CCACHE_DIR=/host${{ secrets.PI_CCACHE_DIR }} ccache -M 10G"
              ;;
            n100)
              CIBW_BEFORE_ALL="$CIBW_BEFORE_ALL && dnf install -y ccache \
                && mkdir -p /host${{ secrets.PVE_CCACHE_DIR }} \
                && CCACHE_DIR=/host${{ secrets.PVE_CCACHE_DIR }} ccache -M 10G"
              ;;
          esac

          export CIBW_BEFORE_ALL
          COMMON_FLAGS="MAX_JOBS=4 CMAKE_BUILD_PARALLEL_LEVEL=4 MAKEFLAGS=-j4"
          case "${{ runner.name }}" in
            pi)
              export CIBW_ENVIRONMENT="$CIBW_ENVIRONMENT CCACHE_DIR=/host${{ secrets.PI_CCACHE_DIR }} $COMMON_FLAGS"
              ;;
            n100)
              export CIBW_ENVIRONMENT="$CIBW_ENVIRONMENT CCACHE_DIR=/host${{ secrets.PVE_CCACHE_DIR }} $COMMON_FLAGS"
              ;;
          esac

          # Image selection based on architecture input
          if [[ "${{ inputs.arch }}" == 'x86_64' ]]; then
            export CIBW_MANYLINUX_X86_64_IMAGE="quay.io/pypa/manylinux_2_28_x86_64:latest"
            docker pull "${CIBW_MANYLINUX_X86_64_IMAGE}"
          else
            export CIBW_MANYLINUX_AARCH64_IMAGE="quay.io/pypa/manylinux_2_28_aarch64:latest"
            docker pull "${CIBW_MANYLINUX_AARCH64_IMAGE}"
          fi
          docker image prune -f

          # Set build/skip from inputs. This is the core of the customization.
          export CIBW_BUILD="${{ inputs.cibw-build }}"
          export CIBW_SKIP="${{ inputs.cibw-skip }}"

          echo "--- CIBW Settings ---"
          echo "CIBW_BUILD: ${CIBW_BUILD}"
          echo "CIBW_SKIP: ${CIBW_SKIP}"
          echo "---------------------"

          rm -rf ./wheelhouse* || :
          if [ -f "python/setup.py" ]; then
            python3 -m cibuildwheel python --output-dir wheelhouse
          else
            python3 -m cibuildwheel . --output-dir wheelhouse
          fi

      - name: Rename and Publish wheels
        if: ${{ steps.check-version.outputs.new_commit == 'true' }}
        working-directory: triton
        env:
          FLA_PYPI_PASSWD: ${{ secrets.FLA_TRITON_PYPI_PASSWD }}
          PACKAGE_NAME: ${{ inputs.package-name }}
        run: |
          cd wheelhouse
          set -e  # Exit immediately if any command fails

          # Flag to track if any wheel processing fails
          ALL_WHEELS_PROCESSED=true
          if [ "${PACKAGE_NAME}" == "triton-nightly" ]; then
            echo "--- Processing Nightly Build: Renaming packages to 'triton-nightly' ---"
            for whl in triton-*.whl; do
              # Create a subshell for error handling
              if (
                set -e
                echo "Processing: $whl"
                wheel unpack "$whl" -d tmp_pkg &&
                OLD_VERSION=$(unzip -p "$whl" *dist-info/METADATA | grep "^Version:" | cut -d' ' -f2) &&
                NEW_VERSION=$(echo "$OLD_VERSION" | sed 's/+git.*$/.dev'"$BUILD_DATE"'/') &&
                mv "tmp_pkg/triton-${OLD_VERSION}" "tmp_pkg/triton_nightly-${NEW_VERSION}" &&
                mv "tmp_pkg/triton_nightly-${NEW_VERSION}/triton-${OLD_VERSION}.dist-info" "tmp_pkg/triton_nightly-${NEW_VERSION}/triton_nightly-${NEW_VERSION}.dist-info" &&
                sed -i -e "s/^Name: triton$/Name: triton-nightly/" -e "s/^Version: ${OLD_VERSION}$/Version: ${NEW_VERSION}/" "tmp_pkg/triton_nightly-${NEW_VERSION}/triton_nightly-${NEW_VERSION}.dist-info/METADATA" &&
                wheel pack "tmp_pkg/triton_nightly-${NEW_VERSION}" -d . --build-number ""
              ); then
                # Successfully processed
                rm -f "$whl"
                echo "Successfully processed: $whl â†’ triton_nightly-${NEW_VERSION}-*.whl"
              else
                # Failed to process this wheel
                ALL_WHEELS_PROCESSED=false
                echo "Failed to process: $whl"
              fi
              # Always clean up temp directory
              rm -rf tmp_pkg
              echo "Successfully processed: $whl"
            done
          else
            echo "--- Processing Release Build: No renaming needed. ---"
            # For release builds, we do nothing to the wheels.
          fi

          # Only upload if ALL wheels were successfully processed
          if [ "$ALL_WHEELS_PROCESSED" = true ]; then
            echo "Uploading wheels via FTP..."
            readarray -d '' -t WHEEL_FILES < <(find . -maxdepth 1 -name "*.whl" -print0)
            if [ ${#WHEEL_FILES[@]} -eq 0 ]; then
              echo "Error: No *.whl files found to upload."
              exit 1
            fi

            lftp -u flapypi,"${{ secrets.FLA_TRITON_PYPI_PASSWD }}" "${{ secrets.FLAPYPIFTP }}" -e "set ftp:ssl-allow no; mput *.whl; bye"

            echo "All *.whl files uploaded successfully via FTP!"
          else
            echo "One or more wheels failed to process. Skipping upload."
            exit 1
          fi
